{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AHamamd150/ML_Course_BUE/blob/main/BUE_2024/codes/VisionTransformer_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "157d96fc",
      "metadata": {
        "id": "157d96fc"
      },
      "source": [
        "# This notebook implements the vision transformer model with an end to end training on fashion mnist datset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd1fef4a",
      "metadata": {
        "id": "bd1fef4a"
      },
      "outputs": [],
      "source": [
        "#please install the keras_nlp to use the transformer encoder\n",
        "%pip install keras_nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "de784638",
      "metadata": {
        "id": "de784638"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "import sys\n",
        "from keras_nlp.layers import TransformerEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "31968bd8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31968bd8",
        "outputId": "083a3ccd-2519-4d5d-ac5b-38449637611b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "x_train: (60000, 28, 28, 1) \n",
            "x_test: (10000, 28, 28, 1)\n",
            "y_train: (60000,)\n",
            "y_test: (10000,)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 10\n",
        "input_shape =(28,28,1)\n",
        "(x_train,y_train),(x_test,y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "x_train = x_train[...,tf.newaxis].astype('float32')\n",
        "x_test = x_test[...,tf.newaxis].astype('float32')\n",
        "loss_func = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "print(f'''x_train: {x_train.shape}\n",
        "x_test: {x_test.shape}\n",
        "y_train: {y_train.shape}\n",
        "y_test: {y_test.shape}''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "20ceb6cc",
      "metadata": {
        "id": "20ceb6cc"
      },
      "outputs": [],
      "source": [
        "batch_size=256\n",
        "kernel_size = 4\n",
        "epoch = 20\n",
        "image_size = 28\n",
        "num_heads = 4\n",
        "num_transformers= 4\n",
        "num_patches = (image_size // kernel_size) ** 2\n",
        "projection_dim = 32\n",
        "mlp_head_units = [256, 128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2ac0e330",
      "metadata": {
        "id": "2ac0e330"
      },
      "outputs": [],
      "source": [
        "class Patches_extraction(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1], ## We can scale the output patches\n",
        "            padding=\"VALID\", ## To not keep the same output dimensions as input one\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims]) # (patch size, num_constit, features)\n",
        "        return patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9513fdfc",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "9513fdfc",
        "outputId": "8b7b8af6-d340-4742-ec5d-58b6cb037232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 28x28\n",
            "Number of patches: 49\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 49 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "b1 = Patches_extraction(kernel_size)(x_train)\n",
        "im_num = 0\n",
        "print(f'Image size: {image_size}x{image_size}')\n",
        "print(f'Number of patches: {len(b1[1])}')\n",
        "\n",
        "n = int(np.sqrt(b1.shape[1]))\n",
        "fig = plt.figure(figsize=(4, 4))\n",
        "for i in range(len(b1[im_num])):\n",
        "    y = fig.add_subplot(n,n,i+1)\n",
        "    patch_im = tf.reshape(b1[im_num][i],(kernel_size,kernel_size,1))\n",
        "    plt.imshow(patch_im)\n",
        "    plt.axis(\"off\")\n",
        "im = x_train[im_num].reshape(28,28)\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(im)\n",
        "plt.axis('off')\n",
        "plt.title('True Image',fontsize=20);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6de2d025",
      "metadata": {
        "id": "6de2d025"
      },
      "outputs": [],
      "source": [
        "### the final MLP layers\n",
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "## Encode the patches with their positions\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7978dbfb",
      "metadata": {
        "id": "7978dbfb"
      },
      "outputs": [],
      "source": [
        "#Initiate the transformer encoder\n",
        "transformer_encoder = TransformerEncoder(intermediate_dim=projection_dim, num_heads=num_heads,dropout=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3f45497a",
      "metadata": {
        "id": "3f45497a"
      },
      "outputs": [],
      "source": [
        "def create_vit_classifier():\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Create patches.\n",
        "    patches = Patches_extraction(kernel_size)(inputs)\n",
        "    # Encode patches.\n",
        "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(num_transformers):\n",
        "        encoded_patches = transformer_encoder(encoded_patches)\n",
        "    # Create a [batch_size, projection_dim] tensor.\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.2)(representation)\n",
        "    # Add MLP.\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.2)\n",
        "    logits = layers.Dense(num_classes)(features)\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3e2bf4fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "3e2bf4fd",
        "outputId": "2130ab24-92d6-477f-da80-a136617a5577"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ patches_extraction_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mPatches_extraction\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ patch_encoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │          \u001b[38;5;34m2,112\u001b[0m │ patches_extraction_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mPatchEncoder\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │          \u001b[38;5;34m6,464\u001b[0m │ patch_encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ transformer_encoder[\u001b[38;5;34m1\u001b[0m… │\n",
              "│                           │                        │                │ transformer_encoder[\u001b[38;5;34m2\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m64\u001b[0m │ transformer_encoder[\u001b[38;5;34m3\u001b[0m… │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1568\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1568\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m401,664\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │          \u001b[38;5;34m1,290\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ patches_extraction_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Patches_extraction</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ patch_encoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ patches_extraction_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchEncoder</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,464</span> │ patch_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>… │\n",
              "│                           │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1568</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1568</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">401,664</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m444,490\u001b[0m (1.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">444,490</span> (1.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m444,490\u001b[0m (1.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">444,490</span> (1.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = create_vit_classifier()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3de44d8d",
      "metadata": {
        "id": "3de44d8d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b61cca0",
      "metadata": {
        "id": "2b61cca0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5dbe9b08",
      "metadata": {
        "id": "5dbe9b08"
      },
      "source": [
        "* Now we have created the ViT model, lets create the train and test loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "da929cb7",
      "metadata": {
        "id": "da929cb7"
      },
      "outputs": [],
      "source": [
        "### Training loop function per training batch\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(x, training=True)\n",
        "        loss_value = loss_func(y, logits)\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    train_accuracy.update_state(y, logits)\n",
        "    return loss_value,train_accuracy.result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "370314b7",
      "metadata": {
        "id": "370314b7"
      },
      "outputs": [],
      "source": [
        "### function to test the loss and accuracy per training batch\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    test_accuracy.update_state(y, val_logits)\n",
        "### Function to the test the model accuracy on the model test data\n",
        "def test_acc(model,x, y):\n",
        "    val_logits = model(x, training=False)\n",
        "    test_accuracy.update_state(y, val_logits)\n",
        "    return print(f'Test Accuracy:  {test_accuracy.result()*100 :.3f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7c876548",
      "metadata": {
        "id": "7c876548"
      },
      "outputs": [],
      "source": [
        "## Define the traning loop\n",
        "\n",
        "def training_loop(model,x_train,y_train,epochs=20,batch_size=512):\n",
        "    ## Lets create the batches first\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(x_train.shape[0]).batch(batch_size)\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n",
        "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "    epoch_acc_avg = tf.keras.metrics.Mean()\n",
        "    for epoch in range(epochs):\n",
        "    # Iterate over the batches of the dataset.\n",
        "        loss,acc = [],[]\n",
        "        for step, (x_batch_train, y_batch_train) in enumerate(train_ds):\n",
        "            loss_value,acc_value = train_step(x_batch_train, y_batch_train)\n",
        "            loss.append(loss_value)\n",
        "            acc.append(acc_value)\n",
        "            epoch_loss_avg.update_state(loss)\n",
        "            epoch_acc_avg.update_state(acc)\n",
        "            if step % 1 == 0:\n",
        "                sys.stdout.write('\\r'+'step %s :  loss = %2.5f  accuracy = %2.5f'%((step + 1),float(loss_value),float(acc_value)))\n",
        "\n",
        "        # Display metrics at the end of each epoch.\n",
        "        tf.print('|   Epoch {:2d}:  Loss (Avg): {:2.5f}  Accuracy (Avg): {:2.5f}'.format(epoch+1,epoch_loss_avg.result(),epoch_acc_avg.result()))\n",
        "        # Reset training metrics at the end of each epoch\n",
        "        train_accuracy.reset_states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39e5200b",
      "metadata": {
        "id": "39e5200b"
      },
      "outputs": [],
      "source": [
        "training_loop(model,x_train,y_train,epochs=epoch,batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a31a21",
      "metadata": {
        "id": "f3a31a21",
        "outputId": "0ec97a4c-7f1a-4d45-94f0-8a8a029d51a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  91.220%\n"
          ]
        }
      ],
      "source": [
        "test_acc(model,x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b16452",
      "metadata": {
        "id": "85b16452"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}